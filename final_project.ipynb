{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b750025-903e-443c-a7d2-2198a797cd7d",
   "metadata": {},
   "source": [
    "# Analysis and Comparison of Tweets: Boston Marathon Bombings vs. Hurricane Sandy\n",
    "\n",
    "- Vicky Xie: Coding: Data Importing/Reading/Processing, Sentiment Analysis, Topic Modeling, pyLDAvis\n",
    "- Riley Smith: Introduction, Topic Analysis, Visualization\n",
    "- Finnley O'Rourke: put their contribution here\n",
    "- Kayla Katakis: Research Questions, Dataset Descriptions, Results/Findings: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f943a9-0647-4388-8a26-ad5666c4e840",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import and Install Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ddbdb4-c1db-4c85-892f-51dd0c3d7cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Using cached textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Collecting nltk>=3.1\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Using cached regex-2023.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (4.65.0)\n",
      "Collecting click\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Installing collected packages: regex, click, nltk, textblob\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datapane 0.16.5 requires pydantic<2.0.0,>=1.6.0, which is not installed.\n",
      "datapane 0.16.5 requires pandas<2.0.0,>=1.1.0, but you have pandas 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed click-8.1.3 nltk-3.8.1 regex-2023.6.3 textblob-0.17.1\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Collecting bokeh\n",
      "  Using cached bokeh-3.1.1-py3-none-any.whl (8.3 MB)\n",
      "Collecting xyzservices>=2021.09.1\n",
      "  Using cached xyzservices-2023.5.0-py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /opt/conda/lib/python3.10/site-packages (from bokeh) (3.1.2)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.10/site-packages (from bokeh) (6.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.10/site-packages (from bokeh) (1.24.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/jovyan/.local/lib/python3.10/site-packages (from bokeh) (2.0.2)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.10/site-packages (from bokeh) (23.0)\n",
      "Requirement already satisfied: contourpy>=1 in /opt/conda/lib/python3.10/site-packages (from bokeh) (1.0.7)\n",
      "Requirement already satisfied: tornado>=5.1 in /opt/conda/lib/python3.10/site-packages (from bokeh) (6.2)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from bokeh) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=2.9->bokeh) (2.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/jovyan/.local/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh) (1.16.0)\n",
      "Installing collected packages: xyzservices, bokeh\n",
      "Successfully installed bokeh-3.1.1 xyzservices-2023.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in /home/jovyan/.local/lib/python3.10/site-packages (3.4.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from pyLDAvis) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pyLDAvis) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.24.2 in /opt/conda/lib/python3.10/site-packages (from pyLDAvis) (1.24.2)\n",
      "Requirement already satisfied: funcy in /home/jovyan/.local/lib/python3.10/site-packages (from pyLDAvis) (2.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from pyLDAvis) (3.1.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pyLDAvis) (2.0.2)\n",
      "Requirement already satisfied: numexpr in /home/jovyan/.local/lib/python3.10/site-packages (from pyLDAvis) (2.8.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pyLDAvis) (67.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from pyLDAvis) (1.2.0)\n",
      "Requirement already satisfied: gensim in /home/jovyan/.local/lib/python3.10/site-packages (from pyLDAvis) (4.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0.0->pyLDAvis) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/jovyan/.local/lib/python3.10/site-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.1.0)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Using cached smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->pyLDAvis) (2.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
      "Installing collected packages: smart-open\n",
      "Successfully installed smart-open-6.3.0\n"
     ]
    }
   ],
   "source": [
    "# Install Neccesary Packages\n",
    "!pip install textblob\n",
    "!pip install nltk \n",
    "!pip install bokeh\n",
    "\n",
    "# Import Necessary Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Downloading and Setting Up the Stopwords Package and Stemmer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "!pip install pyLDAvis\n",
    "import gensim\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4872ee5-9a7c-431e-915e-4617bad79d85",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c9a2f0-032e-4d5c-bb9c-91b123a32d3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Our project focuses on the use of sentiment analysis and natural language processing in order to extract data from tweets regarding the Boston Marathon Bombings and Hurricane Sandy. The datasets observed looks at tweets in the aftermath of the both disasters, some of which are classified as “on topic” and others that are classified as “off-topic”. The “on-topic” tweets refer directly to the bombing or the hurricane while the “off-topic” tweets are about anything else. \n",
    " \n",
    "In order to extrapolate specific types of data from the data set our group used both VaderSentiment and TextBlob which helped create sentiment analysis scores for the various tweets. While both VaderSentiment and TextBlob are repositories that help coders perform sentiment analysis there are a few key differences that create variance within the data. \n",
    "\n",
    "Some of the differences between the two models include sentiment intensity vs. sentiment polarity. VaderSentimet uses a rule-based analysis in order to assign an intensity score (-1 to 1) to a given dataset. In contrast TextBlob uses a few different components like part-of-speech tagging and noun phrase extraction in order to assign a given tweet a polarity score (negative, neutral, or positive). Additionally, VaderSentiment is designed to incorporate other aspects of tweets such as emojis and capitalization which helps the program discern the level of sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cc8c86-9a5d-4c28-b17b-9440736067fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Research Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f555a7ff-68fa-4c5a-b4f4-bca6d0726cb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this project, we will perform sentiment analysis and topic modeling to answer the following questions:\n",
    "- How do Vader and TextBlob differ in creating sentiment scores for on topic tweets in regards to the Boston Marathon Bombings?\n",
    "- How do Vader and TextBlob differ in creating sentiment scores for on-topic tweets about man-made disasters (Boston Marathon Bombing) versus natural disasters (Hurricane Sandy)?\n",
    "- What are the main topic cluster that crop up in the tweets that are ‘on-topic’ in regards to the Boston Marathon Bombings? \n",
    "- How do they compare to the ‘on-topic’ topic clusters in the Hurricane Sandy tweets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851305a7-c792-4876-8000-0724b602e112",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be2ce09-aae9-49bf-b43f-9e5eccbf241a",
   "metadata": {},
   "source": [
    "The Boston Bombings dataset takes looks at just over 10,000 tweets that are either about the Boston Marathon bombings or about other random topics. The Boston Bombings dataset has 3 columns.\n",
    "\n",
    "- `label` - a string that indicates whether or not the tweet/observation is about the Boston Marathon Bombings , can either be ‘on-topic’ or ‘off-topic’\n",
    "- `tweet id` - a string that gives each observation a unique identifier value\n",
    "- `tweet` - a string that  represents the entire text of each unique tweet\n",
    "\n",
    "Using the describe() function, we can see the the number of values for each column (count), and how many of those values are unique (unique). Additionally, we can see the ‘top’ value, which represents the most common value , and its frequency. For this dataset, there are 10,012 tweet id’s that are all unique and 10,012 total tweets, with 9,226 of those being unique. We see that our “top” id value only has a frequency of one, which is intuitive due to the unique nature of that variable. Our “top” tweet is actually a retweet that shows up 34 times in the dataset, meaning that there is likely an original tweet that was retweeted 34 times. There are only two unique “label” values, either on-topic or off-topic, with the more common label being on-topic with a count of 5,648.\n",
    "\n",
    "The Hurricane Sandy dataset is structured identically to the Boston Bombing dataset, with the same 3 columns. The major difference, of course, is that being “on-topic” now refers to tweets that are directly related to Hurricane Sandy as opposed to the Boston Marathon Bombings. \n",
    "\n",
    "Using the describe() function on the Hurricane Sandy dataframe, we can see that there is nearly an equal number of tweets, with Hurricane Sandy having 10,008 tweets, each with their own unique id. Of the 10,008 tweets, 9,431 are unique with two potential labels, either on or off topic, which is the same as before. Similarly to the Boston Bombing data frame, the \"top\" tweet in this dataset is in the form of a retweet with a frequency of 28, meaning there is a likely an original tweet, and its retweets come up 28 times in this dataset. The more common label in this dataset is on-topic with a count of 6,138."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada705f5-1ea0-4b1c-93da-f8a8f2ca7e64",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2013 Boston Bombing DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e7b812-d39f-462d-b618-521e4909f7e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10012</td>\n",
       "      <td>10012</td>\n",
       "      <td>10012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10012</td>\n",
       "      <td>9226</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>'325208201740029952'</td>\n",
       "      <td>RT @DannyAmendola: I will DONATE $100 for EVER...</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>5648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet id  \\\n",
       "count                  10012   \n",
       "unique                 10012   \n",
       "top     '325208201740029952'   \n",
       "freq                       1   \n",
       "\n",
       "                                                    tweet     label  \n",
       "count                                               10012     10012  \n",
       "unique                                               9226         2  \n",
       "top     RT @DannyAmendola: I will DONATE $100 for EVER...  on-topic  \n",
       "freq                                                   34      5648  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bomb=pd.read_csv(\"2013_Boston_Bombings-ontopic_offtopic.csv\")\n",
    "bomb.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73d7f6-aeb0-49e8-816f-d739cf722250",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2012 Sandy Hurricane DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "962f598d-545b-4d5f-b568-2822da0e64fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10008</td>\n",
       "      <td>10008</td>\n",
       "      <td>10008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10008</td>\n",
       "      <td>9431</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>'262596552399396864'</td>\n",
       "      <td>RT @HurricaneSandyw: FOR EVERY 100 RETWEETS, W...</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>6138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet id  \\\n",
       "count                  10008   \n",
       "unique                 10008   \n",
       "top     '262596552399396864'   \n",
       "freq                       1   \n",
       "\n",
       "                                                    tweet     label  \n",
       "count                                               10008     10008  \n",
       "unique                                               9431         2  \n",
       "top     RT @HurricaneSandyw: FOR EVERY 100 RETWEETS, W...  on-topic  \n",
       "freq                                                   28      6138  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandy=pd.read_csv(\"2012_Sandy_Hurricane-ontopic_offtopic.csv\")\n",
    "sandy.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da1dc92-aeb2-4f27-a77d-6433d25b91ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bcf01e-e4fb-4f93-a6ed-844da7cda835",
   "metadata": {},
   "source": [
    "Before we begin analyzing the data, we first need to clean up our `tweet` column to get rid of any unnecessary information. \n",
    "To do so, we wrote a function called clean_text() that removes URLs, hashtags, mentions, and any unnecessary whitespace from the text to make sure that only the most meaningful aspects of the text are left for analysis. \n",
    "\n",
    "Additionally, our research questions revolve entirely around the on-topic tweets, so we will filter our datasets to include only these tweets to make our analysis easier and more efficient. We will also drop any empty tweets from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422a0f79-bbbf-4623-b59e-8665c29d7310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text cleaning\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # remove mentions\n",
    "    text = re.sub(r'#', '', text) # remove hashtag\n",
    "    text = re.sub(r'\\s+', ' ', text)  # remove extra spaces\n",
    "    return text.strip()\n",
    "\n",
    "# Apply cleaning to Boston Bombing df:\n",
    "bomb['clean_text'] = bomb.loc[(bomb[' label'] == 'on-topic')][' tweet'].apply(clean_text)\n",
    "bomb=bomb.dropna(subset = ['clean_text'])\n",
    "\n",
    "# Apply cleaning to Hurrican Sandy df:\n",
    "sandy['clean_text'] = sandy.loc[(sandy[' label'] == 'on-topic')][' tweet'].apply(clean_text)\n",
    "sandy=sandy.dropna(subset = ['clean_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b79ce8b-31b5-4b3e-a118-dc0b5ccc6e32",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Boston Bombing processed text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61a0cea-059f-4caf-8c97-7af87b7df4e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     This is fucking crazy. Suspect 2 has like 2 ho...\n",
       "5     Back Bay Businesses Large And Small Affected B...\n",
       "9     9000 agents/officers working for 14 hours, so ...\n",
       "17    Tough to grasp what's happening right now in ....\n",
       "19    Thank you to everyone who is keeping our city ...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bomb['clean_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc0035-3661-40be-879f-bafb45f0de7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hurricane Sandy processed text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88807f27-5c37-4ea0-8114-ab17988d241f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     Sandy be soooo mad that she be shattering our ...\n",
       "5     Neighborly duties. arrives to the rescue sport...\n",
       "7     I don't know how I'm getting back to Jersey si...\n",
       "10              Already flooded so much SANDY @ Hoboken\n",
       "12    On that note, i pray that everyone stays safe,...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandy['clean_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf42a68-455a-426c-9722-993de158d5c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c8c039-a816-447b-95de-65df216598df",
   "metadata": {
    "tags": []
   },
   "source": [
    "For our analysis, we chose to use Sentiment Analysis and Topic Modeling. Because we are interesteed in the way people tweet about both man-made and natural disasters, we felt that Sentiment Analysis would be a great way to judge how people use Twitter to either sympathize with our create positivity from these disasters. Additionally, Topic Modeling can help us understand what common themes pop up in tweets about these disasters and help us understand how people react when these events occur.\n",
    "\n",
    "These two methods give us insight to how people communicate in the wake of disasters. Specifically, sentiment analysis gives us in-depth and statistical data to interpret initial public reactions and tones. In combination with topic modeling, which gives us the ability to see which subjects are the most popular, researchers are able to gain a more holistic view of how people communicate using Twitter.\n",
    "\n",
    "In this research project Sentiment Analysis and Topic Modeling lay out the largest and most prevalent topics and sentiments in relation to the Boston Bombing and Hurricane Sandy. Furthermore, we will also observe the differences between TextBlob and Vader in order to see how the programs interpreted data differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e048c6-71fb-40a6-9c3e-2fff316c3e1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43446707-46b0-45df-bf15-7f42c80c07a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "In order to carry out our Sentiment Analysis, we first had to develop a few functions that we can then apply to our two datasets using both TextBlob and Vader. \n",
    "\n",
    "Our first function `get_sentiment_textblob()` takes in a text value, which will be each tweet in the dataset, and then using the TextBlob package to return a sentiment score label. Any score greater than 0 is 'Positive' sentiment, less than 0 is 'Negative', and equal to 0 is 'Neutral'. Our other TextBlob function, `get_sent_textblob_cont()` takes each tweet and returns the numerical, continuous sentiment score.\n",
    "\n",
    "We also have `get_sentiment_vader()` that works the same way and gives tweets a 'Positive' label to tweets with a score of 0.05 or higher, 'Negative' when the score is less than -0.05, and 'Neutral' if the score is between those two values. Since the Vader library uses more aspects of the tweets, such as capitalizations and emojis, we chose to give the Vader functions a slightly wider range for neutral tweets to account for the larger scope of variables that go into calculating the score.  Similarly to its TextBlob counterpart, `get_sent_vader_cont()` takes each tweet and returns its numerical, continuous sentiment score.\n",
    "\n",
    "Then we apply all four of our functions to each of our two datasets to create dataframes that include each unique tweet and the sentiment scores and labels from each library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e2a1e04-3ccb-4eff-9e26-6a6a812cb5de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function for sentiment analysis using TextBlob\n",
    "def get_sentiment_textblob(text):\n",
    "    \"\"\"\n",
    "    this function takes text as the input and calculates the sentiment score of this given text.\n",
    "    \"\"\"\n",
    "    sentiment = TextBlob(text).sentiment.polarity\n",
    "    if sentiment > 0:\n",
    "        return \"Positive\"\n",
    "    elif sentiment < 0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# get continuous textblob sentiment scores\n",
    "def get_sent_textblob_cont(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Define a function for sentiment analysis using NLTK's Vader\n",
    "def get_sentiment_vader(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    if sentiment['compound'] > 0.05:\n",
    "        return \"Positive\"\n",
    "    elif sentiment['compound'] < -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "    \n",
    "# get continuous vader sentiment scores\n",
    "def get_sent_vader_cont(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    return sia.polarity_scores(text)['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5c79d-be71-4330-99a6-89521cf6f921",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Boston Bombing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f0b601a-9ce3-41f1-865c-2c9513290673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sentiment_textblob</th>\n",
       "      <th>sent_textblob_cont</th>\n",
       "      <th>sentiment_vader</th>\n",
       "      <th>sent_vader_cont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is fucking crazy. Suspect 2 has like 2 ho...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.3962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Back Bay Businesses Large And Small Affected B...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.011905</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9000 agents/officers working for 14 hours, so ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.5233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Tough to grasp what's happening right now in ....</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.132275</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.8519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Thank you to everyone who is keeping our city ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.8271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>RT : Boston bombing suspects’ dad says sons we...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10008</th>\n",
       "      <td>Like the boston marathon, on a episode peter h...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>RT : MUST WATCH: Bruins fans sing emotional Na...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>RT : So that Boston bombing was fake just like...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>RT : Both FBI and al Qaeda struggling to ident...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.4215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5648 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_text sentiment_textblob  \\\n",
       "2      This is fucking crazy. Suspect 2 has like 2 ho...           Negative   \n",
       "5      Back Bay Businesses Large And Small Affected B...           Negative   \n",
       "9      9000 agents/officers working for 14 hours, so ...           Positive   \n",
       "17     Tough to grasp what's happening right now in ....           Positive   \n",
       "19     Thank you to everyone who is keeping our city ...           Positive   \n",
       "...                                                  ...                ...   \n",
       "10007  RT : Boston bombing suspects’ dad says sons we...           Negative   \n",
       "10008  Like the boston marathon, on a episode peter h...            Neutral   \n",
       "10009  RT : MUST WATCH: Bruins fans sing emotional Na...           Negative   \n",
       "10010  RT : So that Boston bombing was fake just like...           Negative   \n",
       "10011  RT : Both FBI and al Qaeda struggling to ident...           Negative   \n",
       "\n",
       "       sent_textblob_cont sentiment_vader  sent_vader_cont  \n",
       "2               -0.600000        Negative          -0.3962  \n",
       "5               -0.011905        Negative          -0.1531  \n",
       "9                0.200000        Positive           0.5233  \n",
       "17               0.132275        Positive           0.8519  \n",
       "19               0.500000        Positive           0.8271  \n",
       "...                   ...             ...              ...  \n",
       "10007           -0.250000         Neutral           0.0000  \n",
       "10008            0.000000        Negative          -0.4939  \n",
       "10009           -0.050000        Positive           0.1531  \n",
       "10010           -0.500000        Negative          -0.1531  \n",
       "10011           -0.400000        Negative          -0.4215  \n",
       "\n",
       "[5648 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply Sentiment Analysis functions to the Boston Bombings dataset\n",
    "bomb['sentiment_textblob'] = bomb['clean_text'].apply(get_sentiment_textblob)\n",
    "bomb['sent_textblob_cont'] = bomb['clean_text'].apply(get_sent_textblob_cont)\n",
    "bomb['sentiment_vader'] = bomb['clean_text'].apply(get_sentiment_vader)\n",
    "bomb['sent_vader_cont'] = bomb['clean_text'].apply(get_sent_vader_cont)\n",
    "bomb[[\"clean_text\", \"sentiment_textblob\", \"sent_textblob_cont\", \"sentiment_vader\", \"sent_vader_cont\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db197fb-b066-497f-a74c-b05c7c0306ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hurricane Sandy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b17b80-ea04-4785-8745-28b7f25a5dcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Applying Sentiment Analysis Functions to Hurricane Sandy Dataset\n",
    "sandy['sentiment_textblob'] = sandy['clean_text'].apply(get_sentiment_textblob)\n",
    "sandy['sent_textblob_cont'] = sandy['clean_text'].apply(get_sent_textblob_cont)\n",
    "sandy['sentiment_vader'] = sandy['clean_text'].apply(get_sentiment_vader)\n",
    "sandy['sent_vader_cont'] = sandy['clean_text'].apply(get_sent_vader_cont)\n",
    "sandy[[\"clean_text\", \"sentiment_textblob\", \"sent_textblob_cont\", \"sentiment_vader\", \"sent_vader_cont\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640aab84-7999-4f0c-987d-a7a5689cef6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee25659-6d8b-4f70-aaa6-fac828286b40",
   "metadata": {},
   "source": [
    "To analyze the difference between Vader and TextBlob in creating sentiment scores, we used bar plots that are color coded to represent the different libraries. TextBlob counts are shown in mediumturquoise, Vader in yellowgreen, and any overlapping counts are shown in green. To create these plots, we used Seaborns countplot() function to create two layers of the plot, one with the continuous scores from the TextBlob functions, and one with the continous scores from Vader. \n",
    "\n",
    "The data reveals that there is a significant difference in the way that each program caluculated the scores. In relation to the Boston Bombings Vader observed significantly more \"Negative\" sentiments than TextBlob. Conversely, TextBlob recorded a much larger sample of \"Neutral\" Tweets. However the two programs recognized a similar amount of tweets with a \"Positive\" Sentiment. \n",
    "\n",
    "For Hurricane Sandy both Vader and TextBlob had significantly less Variane within the data. There was not a notable difference in the detection and sorting of different sentiments. Vader detected a slightly larger amount of \"Positive\" tweets, while TextBlob had more \"Negative\". But both programs had a very similar amount of responses with a \"Neutral\" connotation. The data is much more uniform when compaared to the Boston Bombings. It also indicates that people might be more likely the have similar opinions on Natural Disatsers rather than Man Made Disasters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e4dc3-6ca9-4779-ab1c-0dc938c1fc1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Boston Bombing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce58c4e7-c515-43c3-91e5-c8bfeb6ec465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=\"sentiment_textblob\", data= bomb , label=\"TextBlob\", color='mediumturquoise', alpha=0.5)\n",
    "sns.countplot(x=\"sentiment_vader\", data= bomb , label=\"Vader\", color='yellowgreen', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.title('Distribution of Sentiment Scores from TextBlob and Vader: Boston Bombings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b776783-c4bc-482a-a939-64200f7fe3b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hurricane Sandy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f3067-234b-407f-b2b9-84f85fe2f15a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=\"sentiment_textblob\", data=sandy, label=\"TextBlob\", color='mediumturquoise', alpha=0.5)\n",
    "sns.countplot(x=\"sentiment_vader\", data=sandy , label=\"Vader\", color='yellowgreen', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.title('Distribution of Sentiment Scores from TextBlob and Vader: Hurricane Sandy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea61b7-b558-4ae5-b424-19153ea558e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed10a9d1-7b5d-44d8-87ae-e11ab7a739a9",
   "metadata": {},
   "source": [
    "- Add your explanations in here\n",
    "- because we're using 2 datasets, its essential to clearly differentiate the functions with _boom and _natural to prevent errors when running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40a7e6c-dae2-4124-bb0d-1113df530339",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Boston Bombing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3835c-af15-46f6-911a-6fa76cd399d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# We will only use the 'text_cleaned' column for our analysis\n",
    "boom = bomb['clean_text']\n",
    "\n",
    "# Fit and transform the processed titles\n",
    "count_data_boom = count_vectorizer.fit_transform(boom)\n",
    "\n",
    "# Tweak the two parameters below (use int values below 15)\n",
    "number_topics = 5\n",
    "number_words = 10\n",
    "\n",
    "# Create and fit the LDA model with a fixed random state to prevent changes with every update\n",
    "lda_model = LDA(n_components=number_topics, n_jobs=-1, random_state=5)\n",
    "lda_model.fit(count_data_boom)\n",
    "\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names_out()\n",
    "    topic_word_distributions = model.components_\n",
    "    for topic_idx, topic in enumerate(topic_word_distributions):\n",
    "        print(\"\\nTopic #%d:\" % (topic_idx + 1))\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "\n",
    "print_topics(lda_model, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dc41c9-5da1-4984-b87f-67bb06a56d2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "The data reveals that the top 5 Subjects in the Bosston Bombings are: \n",
    "\n",
    "Topic #1:\n",
    "boston rt marathon bombing bomb suspect breaking suspects explosions news\n",
    "\n",
    "- This topic surrounds the initial breaking news of the Boston Bombing. \n",
    "- It surrounds the actual events and actions of the day. \n",
    "- Terms like \"breaking\", \"explosions\", and \"news\" indicate that this event had just \n",
    "occured. \n",
    "\n",
    "\n",
    "Topic #2:\n",
    "boston rt prayforboston marathon old died explosions year people running\n",
    "\n",
    "- This topic surrounds some of the shock and sympathy in the aftermath of the attack. \n",
    "- Users shared their thoughts and prayers through the use of terms like \"#prayforboston\", \"died\", and \"people\".\n",
    "\n",
    "\n",
    "Topic #3:\n",
    "boston rt marathon suspects bombing fbi bombings prayforboston thoughts bostonmarathon\n",
    "\n",
    "- This topic looks at the actual events following the Bombing. \n",
    "- They indicate that the public was sharing information in relation to the initial response to the attack. \n",
    "- Terms like, \"suspects\", \"fbi\", and \"bombing\" demonstrate that the public discourse surrounded justice and resolution. \n",
    "\n",
    "\n",
    "Topic #4:\n",
    "boston rt suspect bombing marathon police bostonmarathon dead bomb suspects\n",
    "\n",
    "- This topic is specifically focussed on the response of law enforcement. \n",
    "- It relates to how the FBI and Boston PD were attempting to locate the extremists. \n",
    "- Terms such as \"suspect\", \"police\", and \"suspects\" demonstrate this.\n",
    "\n",
    "\n",
    "Topic #5:\n",
    "boston rt bombing explosion bostonmarathon obama texas prayforboston martin right\n",
    "\n",
    "- This topic surrounds the political response in the aftermath of the Boston Bombing. \n",
    "- It references aspects of politics through terms like \"Obama\" and \"right\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a895b0-6e92-47c6-8b4c-4c2fbb77fa7f",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec78e31-7fa3-436c-b635-22865132bb52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get topic weights\n",
    "topic_weights = lda_model.transform(count_data_boom)\n",
    "\n",
    "# Array of topic weights    \n",
    "arr_boom = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "arr_boom = arr_boom[np.amax(arr_boom, axis=1) > 0.35]\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "topic_num_boom = np.argmax(arr_boom, axis=1)\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model_boom = TSNE(n_components=2, verbose=1, random_state=5, angle=.99, init='pca')\n",
    "tsne_lda_boom = tsne_model_boom.fit_transform(arr_boom)\n",
    "\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import Legend\n",
    "\n",
    "# Plot the Topic Clusters using Bokeh\n",
    "output_notebook()\n",
    "mycolors_boom = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "plot_boom = figure(title=\"Clustering of Top {} Boston Bombing Topics\".format(number_words), \n",
    "              width=900, height=700)\n",
    "\n",
    "scatter_list_boom = []\n",
    "for topic in np.unique(topic_num_boom):\n",
    "    indices = np.where(topic_num_boom == topic)[0]\n",
    "    scatter = plot_boom.scatter(x=tsne_lda_boom[indices, 0], \n",
    "                                y=tsne_lda_boom[indices, 1], \n",
    "                                color=mycolors_boom[topic])\n",
    "    scatter_list_boom.append(scatter)\n",
    "\n",
    "# Define topic labels\n",
    "topic_labels_boom = ['Initial Breaking News', 'Public Sympathy', 'Aftershock', 'Law Enforcement', 'Politics']\n",
    "\n",
    "# Create legend\n",
    "legend_boom = Legend(items=[(label, [scatter]) for label, scatter in zip(topic_labels_boom, scatter_list_boom)],\n",
    "                location='top_left')\n",
    "plot_boom.add_layout(legend_boom, 'right')\n",
    "\n",
    "show(plot_boom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf5ada-4815-459d-b74a-70971bda8d8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## pyLDAvis with Boston Marathon Bombing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f7553-8173-4147-8b69-41f4547ecdc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit and transform the processed titles\n",
    "count_data_boom = count_vectorizer.fit_transform(boom)\n",
    "\n",
    "# Convert the count data to a gensim corpus\n",
    "corpus = gensim.matutils.Sparse2Corpus(count_data_boom.T)\n",
    "\n",
    "# Create a gensim Dictionary\n",
    "dictionary = gensim.corpora.Dictionary.from_corpus(corpus, id2word=dict(zip(range(len(count_vectorizer.get_feature_names_out())), count_vectorizer.get_feature_names_out())))\n",
    "\n",
    "# Create and fit the LDA model with gensim\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=number_topics, random_state=5)\n",
    "\n",
    "# Generate the pyLDAvis visualization\n",
    "panel = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(panel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca8c11fa-ee8b-4074-b21c-300f7feebd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Topic Analysis here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9465fe4-6f71-488b-950a-4edd4e90fe34",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hurricane Sandy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6748e787-ae28-4412-9ceb-03ca1a016e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will only use the 'text_cleaned' column for our analysis\n",
    "natural = sandy['clean_text']\n",
    "\n",
    "# Fit and transform the processed titles\n",
    "count_data_natural = count_vectorizer.fit_transform(natural)\n",
    "\n",
    "# Tweak the two parameters below (use int values below 15)\n",
    "number_topics = 5\n",
    "number_words = 10\n",
    "\n",
    "# Create and fit the LDA model with a fixed random state to prevent changes with every update\n",
    "lda_model = LDA(n_components=number_topics, n_jobs=-1, random_state=5)\n",
    "lda_model.fit(count_data_natural)\n",
    "\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names_out()\n",
    "    topic_word_distributions = model.components_\n",
    "    for topic_idx, topic in enumerate(topic_word_distributions):\n",
    "        print(\"\\nTopic #%d:\" % (topic_idx + 1))\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "\n",
    "print_topics(lda_model, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09b64495-c877-4657-b113-8231cecc9d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### add explanation about top 5 topics about Hurricane Sandy here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7779209-1027-4176-952e-d15f5f3ac0f3",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbcc0a8-7cf7-4e6d-9076-78eb00345e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get topic weights\n",
    "topic_weights = lda_model.transform(count_data_natural)\n",
    "\n",
    "# Array of topic weights    \n",
    "arr_natural = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "arr_natural = arr_natural[np.amax(arr_natural, axis=1) > 0.35]\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "topic_num_natural = np.argmax(arr_natural, axis=1)\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model_natural = TSNE(n_components=2, verbose=1, random_state=5, angle=.99, init='pca')\n",
    "tsne_lda_natural = tsne_model_natural.fit_transform(arr_natural)\n",
    "\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import Legend\n",
    "\n",
    "# Plot the Topic Clusters using Bokeh\n",
    "output_notebook()\n",
    "mycolors_natural = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "plot_natural = figure(title=\"Clustering of Top {} Natural Disaster Topics\".format(number_words), \n",
    "              width=900, height=700)\n",
    "\n",
    "scatter_list_natural = []\n",
    "for topic in np.unique(topic_num_natural):\n",
    "    indices = np.where(topic_num_natural == topic)[0]\n",
    "    scatter = plot_natural.scatter(x=tsne_lda_natural[indices, 0], \n",
    "                                y=tsne_lda_natural[indices, 1], \n",
    "                                color=mycolors_natural[topic])\n",
    "    scatter_list_natural.append(scatter)\n",
    "\n",
    "# Define topic labels\n",
    "topic_labels_natural = ['Topic 1', 'Topic 2', 'Topic 3', 'Topic 4', 'Topic 5']\n",
    "\n",
    "# Create legend\n",
    "legend_natural = Legend(items=[(label, [scatter]) for label, scatter in zip(topic_labels_natural, scatter_list_natural)],\n",
    "                location='top_left')\n",
    "plot_natural.add_layout(legend_natural, 'right')\n",
    "\n",
    "show(plot_natural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c8ee4-b910-40df-b734-f9e132d63b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Insert topic analysis here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68519db9-817f-41da-80d7-a61494991460",
   "metadata": {
    "tags": []
   },
   "source": [
    "## pyLDAvis with Hurricane Sandy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c557f-2462-470a-8eee-9e097c9c725e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit and transform the processed titles\n",
    "count_data_natural = count_vectorizer.fit_transform(natural)\n",
    "\n",
    "# Convert the count data to a gensim corpus\n",
    "corpus = gensim.matutils.Sparse2Corpus(count_data_natural.T)\n",
    "\n",
    "# Create a gensim Dictionary\n",
    "dictionary = gensim.corpora.Dictionary.from_corpus(corpus, id2word=dict(zip(range(len(count_vectorizer.get_feature_names_out())), count_vectorizer.get_feature_names_out())))\n",
    "\n",
    "# Create and fit the LDA model with gensim\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=number_topics, random_state=5)\n",
    "\n",
    "# Generate the pyLDAvis visualization\n",
    "panel = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b03bac-3518-4097-adf6-b5f3061cfb7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Results/Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfbfe45-a183-4c1f-82ce-50cf2d13a4fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sentiment Analysis\n",
    "Taking a look at our first research question, we can see that there are major disparities in the way that TextBlob and Vader calculate sentiment scores for the Boston Bombings tweets. Vader produced nearly twice as many \"negative\" labels as TextBlob, while the opposite effect occurred in \"neutral\" tweets. The positive tweets from both libraries are much fewer in frequencies, but TextBlob and Vader label them very similarly. Since Vader has a wider scope of what gets included in calculating the score, it would be a reasonable assumption that the emojis and capitalizations used in these tweets provide more negative context in a addition to the words written. Without these non-textual cues and components, these tweets can be defined as more neutral as they are in TextBlob's processing. In other words, these disparities in how the tweets are processed can show us how important non-textual aspects of written communication can be important in understanding context.\n",
    "\n",
    "In regards to comparing TextBlob and Vader's processing capabilities between man-made (Boston Bombing) and natural (Hurricane Sandy) disasters, we can clearly see a lot less variability between the two libraries when it comes to Hurricane Sandy. The overall trends are the same with Hurricane Sandy as they are with the Bombings: Vader produces more negative labels while TextBlob produces more positive and neutral labels. However, these differences are much less significant, the counts for labels are distribtued much more evenly. Opposite to the Boston Bombings, the most popular label was \"Positive\", which may imply that negative feelings to Hurricane Sandy, a natural disaster, are not as intense or prevalent as feelings toward a man-made disaster such as the Boston Bombings. Since we can connect the Boston Bombings to rhuman emotion and morality more easily than we can with Hurricane Sandy, these assumptions are logically sensible, but not able to be definitively made based on these types of analyses.\n",
    "\n",
    "Further research could be done to investigate the causes of these discrepancies and would be a great pathway into understand how connecting disaster with humanity may influence the tweets that we post and the feelings we share when disaster strikes, but it's safe to say that TextBlob and Vader's different processing abilities give insight to how emojis can change the sentiments of tweets.\n",
    "\n",
    "\n",
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1bad11-5a68-4d38-a00b-90105e453927",
   "metadata": {},
   "source": [
    "- Insert topic modeling results here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
