{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b750025-903e-443c-a7d2-2198a797cd7d",
   "metadata": {},
   "source": [
    "# Analysis and Comparison of Tweets: Boston Marathon Bombings vs. Hurricane Sandy\n",
    "\n",
    "- Vicky Xie: Coding: Data Importing/Reading/Processing, Sentiment Analysis, Topic Modeling, pyLDAvis\n",
    "- Riley Smith: Introduction, Topic Analysis, Visualization\n",
    "- Finnley O'Rourke: Results/Findings: Topic Modeling\n",
    "- Kayla Katakis: Research Questions, Dataset Descriptions, Results/Findings: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f943a9-0647-4388-8a26-ad5666c4e840",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import and Install Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ddbdb4-c1db-4c85-892f-51dd0c3d7cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: textblob in /opt/conda/lib/python3.10/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.10/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (4.65.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: bokeh in /opt/conda/lib/python3.10/site-packages (3.1.1)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /opt/conda/lib/python3.10/site-packages (from bokeh) (2023.5.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.10/site-packages (from bokeh) (1.5.3)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.10/site-packages (from bokeh) (23.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.10/site-packages (from bokeh) (1.24.2)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /opt/conda/lib/python3.10/site-packages (from bokeh) (3.1.2)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from bokeh) (9.4.0)\n",
      "Requirement already satisfied: tornado>=5.1 in /opt/conda/lib/python3.10/site-packages (from bokeh) (6.2)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.10/site-packages (from bokeh) (6.0)\n",
      "Requirement already satisfied: contourpy>=1 in /opt/conda/lib/python3.10/site-packages (from bokeh) (1.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=2.9->bokeh) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.2->bokeh) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pyLDAvis\n",
      "  Using cached pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pyLDAvis) (67.4.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from pyLDAvis) (3.1.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from pyLDAvis) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pyLDAvis) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from pyLDAvis) (1.2.0)\n",
      "Requirement already satisfied: funcy in /opt/conda/lib/python3.10/site-packages (from pyLDAvis) (2.0)\n",
      "Collecting pandas>=2.0.0\n",
      "  Using cached pandas-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "Requirement already satisfied: numpy>=1.24.2 in /opt/conda/lib/python3.10/site-packages (from pyLDAvis) (1.24.2)\n",
      "Requirement already satisfied: numexpr in /opt/conda/lib/python3.10/site-packages (from pyLDAvis) (2.8.4)\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (from pyLDAvis) (4.3.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0.0->pyLDAvis) (2022.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.1.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim->pyLDAvis) (6.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->pyLDAvis) (2.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pandas, pyLDAvis\n",
      "  Attempting uninstall: pandas\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: pandas 1.5.3\n",
      "    Uninstalling pandas-1.5.3:\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: 'installed-files.txt'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ndas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyLDAvis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install pyLDAvis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgensim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyLDAvis'"
     ]
    }
   ],
   "source": [
    "# Install Neccesary Packages\n",
    "!pip install textblob\n",
    "!pip install nltk \n",
    "!pip install bokeh\n",
    "\n",
    "# Import Necessary Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Downloading and Setting Up the Stopwords Package and Stemmer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "!pip install pyLDAvis\n",
    "import gensim\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4872ee5-9a7c-431e-915e-4617bad79d85",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c9a2f0-032e-4d5c-bb9c-91b123a32d3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Our project focuses on the use of Sentiment Analysis and Natural Language Processing in order to extract data from tweets regarding the Boston Marathon Bombings and Hurricane Sandy. The datasets observed look at tweets in the aftermath of both disasters, some of which are classified as “on topic” and others that are classified as “off-topic”. The “on-topic” tweets refer directly to the bombing or the hurricane while the “off-topic” tweets are about anything else. \n",
    " \n",
    "In order to extrapolate specific types of data from the data set our group used both VaderSentiment and TextBlob which helped create Sentiment Analysis scores for the various tweets. While both VaderSentiment and TextBlob are repositories that help coders perform Sentiment Analysis there are a few key differences that create variance within the data. \n",
    "\n",
    "Some of the differences between the two models include sentiment intensity vs. sentiment polarity. VaderSentimet uses a rule-based analysis in order to assign an intensity score (-1 to 1) to a given dataset. In contrast TextBlob uses a few different components like part-of-speech tagging and noun phrase extraction in order to assign a given tweet a polarity score (negative, neutral, or positive). Additionally, VaderSentiment is designed to incorporate other aspects of tweets such as emojis and capitalization which helps the program discern the level of sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cc8c86-9a5d-4c28-b17b-9440736067fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Research Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f555a7ff-68fa-4c5a-b4f4-bca6d0726cb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this project, we will perform sentiment analysis and topic modeling to answer the following questions:\n",
    "- How do Vader and TextBlob differ in creating sentiment scores for on topic tweets in regards to the Boston Marathon Bombings?\n",
    "- How do Vader and TextBlob differ in creating sentiment scores for on-topic tweets about man-made disasters (Boston Marathon Bombing) versus natural disasters (Hurricane Sandy)?\n",
    "- What are the main topic cluster that crop up in the tweets that are ‘on-topic’ in regards to the Boston Marathon Bombings? \n",
    "- How do they compare to the ‘on-topic’ topic clusters in the Hurricane Sandy tweets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851305a7-c792-4876-8000-0724b602e112",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be2ce09-aae9-49bf-b43f-9e5eccbf241a",
   "metadata": {},
   "source": [
    "The Boston Bombings dataset takes looks at just over 10,000 tweets that are either about the Boston Marathon bombings or about other random topics. The Boston Bombings dataset has 3 columns.\n",
    "\n",
    "- `label` - a string that indicates whether or not the tweet/observation is about the Boston Marathon Bombings , can either be ‘on-topic’ or ‘off-topic’\n",
    "- `tweet id` - a string that gives each observation a unique identifier value\n",
    "- `tweet` - a string that  represents the entire text of each unique tweet\n",
    "\n",
    "Using the describe() function, we can see the the number of values for each column (count), and how many of those values are unique (unique). Additionally, we can see the ‘top’ value, which represents the most common value , and its frequency. For this dataset, there are 10,012 tweet id’s that are all unique and 10,012 total tweets, with 9,226 of those being unique. We see that our “top” id value only has a frequency of one, which is intuitive due to the unique nature of that variable. Our “top” tweet is actually a retweet that shows up 34 times in the dataset, meaning that there is likely an original tweet that was retweeted 34 times. There are only two unique “label” values, either on-topic or off-topic, with the more common label being on-topic with a count of 5,648.\n",
    "\n",
    "The Hurricane Sandy dataset is structured identically to the Boston Bombing dataset, with the same 3 columns. The major difference, of course, is that being “on-topic” now refers to tweets that are directly related to Hurricane Sandy as opposed to the Boston Marathon Bombings. \n",
    "\n",
    "Using the describe() function on the Hurricane Sandy dataframe, we can see that there is nearly an equal number of tweets, with Hurricane Sandy having 10,008 tweets, each with their own unique id. Of the 10,008 tweets, 9,431 are unique with two potential labels, either on or off topic, which is the same as before. Similarly to the Boston Bombing data frame, the \"top\" tweet in this dataset is in the form of a retweet with a frequency of 28, meaning there is a likely an original tweet, and its retweets come up 28 times in this dataset. The more common label in this dataset is on-topic with a count of 6,138."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada705f5-1ea0-4b1c-93da-f8a8f2ca7e64",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2013 Boston Bombing DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e7b812-d39f-462d-b618-521e4909f7e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bomb=pd.read_csv(\"2013_Boston_Bombings-ontopic_offtopic.csv\")\n",
    "bomb.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73d7f6-aeb0-49e8-816f-d739cf722250",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2012 Sandy Hurricane DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962f598d-545b-4d5f-b568-2822da0e64fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sandy=pd.read_csv(\"2012_Sandy_Hurricane-ontopic_offtopic.csv\")\n",
    "sandy.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da1dc92-aeb2-4f27-a77d-6433d25b91ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bcf01e-e4fb-4f93-a6ed-844da7cda835",
   "metadata": {},
   "source": [
    "Before we begin analyzing the data, we first need to clean up our `tweet` column to get rid of any unnecessary information. \n",
    "To do so, we wrote a function called clean_text() that removes URLs, hashtags, mentions, and any unnecessary whitespace from the text to make sure that only the most meaningful aspects of the text are left for analysis. \n",
    "\n",
    "Additionally, our research questions revolve entirely around the on-topic tweets, so we will filter our datasets to include only these tweets to make our analysis easier and more efficient. We will also drop any empty tweets from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a0f79-bbbf-4623-b59e-8665c29d7310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text cleaning\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # remove mentions\n",
    "    text = re.sub(r'#', '', text) # remove hashtag\n",
    "    text = re.sub(r'\\s+', ' ', text)  # remove extra spaces\n",
    "    return text.strip()\n",
    "\n",
    "# Apply cleaning to Boston Bombing df:\n",
    "bomb['clean_text'] = bomb.loc[(bomb[' label'] == 'on-topic')][' tweet'].apply(clean_text)\n",
    "bomb=bomb.dropna(subset = ['clean_text'])\n",
    "\n",
    "# Apply cleaning to Hurrican Sandy df:\n",
    "sandy['clean_text'] = sandy.loc[(sandy[' label'] == 'on-topic')][' tweet'].apply(clean_text)\n",
    "sandy=sandy.dropna(subset = ['clean_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b79ce8b-31b5-4b3e-a118-dc0b5ccc6e32",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Boston Bombing processed text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a0cea-059f-4caf-8c97-7af87b7df4e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bomb['clean_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc0035-3661-40be-879f-bafb45f0de7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hurricane Sandy processed text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88807f27-5c37-4ea0-8114-ab17988d241f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sandy['clean_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf42a68-455a-426c-9722-993de158d5c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c8c039-a816-447b-95de-65df216598df",
   "metadata": {
    "tags": []
   },
   "source": [
    "For our analysis, we chose to use Sentiment Analysis and Topic Modeling. Because we are interested in the way people tweet about both man-made and natural disasters, we felt that Sentiment Analysis would be a great way to judge how people use Twitter to either sympathize with our create positivity from these disasters. Additionally, Topic Modeling can help us understand what common themes pop up in tweets about these disasters and help us understand how people react when these events occur.\n",
    "\n",
    "These two methods give us insight to how people communicate in the wake of disasters. Specifically, sentiment analysis gives us in-depth and statistical data to interpret initial public reactions and tones. In combination with topic modeling, which gives us the ability to see which subjects are the most popular, researchers are able to gain a more holistic view of how people communicate using Twitter.\n",
    "\n",
    "In this research project Sentiment Analysis and Topic Modeling lay out the largest and most prevalent topics and sentiments in relation to the Boston Bombing and Hurricane Sandy. Furthermore, we will also observe the differences between TextBlob and Vader in order to see how the programs interpreted data differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e048c6-71fb-40a6-9c3e-2fff316c3e1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43446707-46b0-45df-bf15-7f42c80c07a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "In order to carry out our Sentiment Analysis, we first had to develop a few functions that we can then apply to our two datasets using both TextBlob and Vader. \n",
    "\n",
    "Our first function `get_sentiment_textblob()` takes in a text value, which will be each tweet in the dataset, and then using the TextBlob package to return a sentiment score label. Any score greater than 0 is 'Positive' sentiment, less than 0 is 'Negative', and equal to 0 is 'Neutral'. Our other TextBlob function, `get_sent_textblob_cont()` takes each tweet and returns the numerical, continuous sentiment score.\n",
    "\n",
    "We also have `get_sentiment_vader()` that works the same way and gives tweets a 'Positive' label to tweets with a score of 0.05 or higher, 'Negative' when the score is less than -0.05, and 'Neutral' if the score is between those two values. Since the Vader library uses more aspects of the tweets, such as capitalizations and emojis, we chose to give the Vader functions a slightly wider range for neutral tweets to account for the larger scope of variables that go into calculating the score.  Similarly to its TextBlob counterpart, `get_sent_vader_cont()` takes each tweet and returns its numerical, continuous sentiment score.\n",
    "\n",
    "Then we apply all four of our functions to each of our two datasets to create dataframes that include each unique tweet and the sentiment scores and labels from each library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2a1e04-3ccb-4eff-9e26-6a6a812cb5de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function for sentiment analysis using TextBlob\n",
    "def get_sentiment_textblob(text):\n",
    "    \"\"\"\n",
    "    this function takes text as the input and calculates the sentiment score of this given text.\n",
    "    \"\"\"\n",
    "    sentiment = TextBlob(text).sentiment.polarity\n",
    "    if sentiment > 0:\n",
    "        return \"Positive\"\n",
    "    elif sentiment < 0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# get continuous textblob sentiment scores\n",
    "def get_sent_textblob_cont(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Define a function for sentiment analysis using NLTK's Vader\n",
    "def get_sentiment_vader(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    if sentiment['compound'] > 0.05:\n",
    "        return \"Positive\"\n",
    "    elif sentiment['compound'] < -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "    \n",
    "# get continuous vader sentiment scores\n",
    "def get_sent_vader_cont(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    return sia.polarity_scores(text)['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5c79d-be71-4330-99a6-89521cf6f921",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Boston Bombing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b601a-9ce3-41f1-865c-2c9513290673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Apply Sentiment Analysis functions to the Boston Bombings dataset\n",
    "bomb['sentiment_textblob'] = bomb['clean_text'].apply(get_sentiment_textblob)\n",
    "bomb['sent_textblob_cont'] = bomb['clean_text'].apply(get_sent_textblob_cont)\n",
    "bomb['sentiment_vader'] = bomb['clean_text'].apply(get_sentiment_vader)\n",
    "bomb['sent_vader_cont'] = bomb['clean_text'].apply(get_sent_vader_cont)\n",
    "bomb[[\"clean_text\", \"sentiment_textblob\", \"sent_textblob_cont\", \"sentiment_vader\", \"sent_vader_cont\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db197fb-b066-497f-a74c-b05c7c0306ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hurricane Sandy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b17b80-ea04-4785-8745-28b7f25a5dcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Applying Sentiment Analysis Functions to Hurricane Sandy Dataset\n",
    "sandy['sentiment_textblob'] = sandy['clean_text'].apply(get_sentiment_textblob)\n",
    "sandy['sent_textblob_cont'] = sandy['clean_text'].apply(get_sent_textblob_cont)\n",
    "sandy['sentiment_vader'] = sandy['clean_text'].apply(get_sentiment_vader)\n",
    "sandy['sent_vader_cont'] = sandy['clean_text'].apply(get_sent_vader_cont)\n",
    "sandy[[\"clean_text\", \"sentiment_textblob\", \"sent_textblob_cont\", \"sentiment_vader\", \"sent_vader_cont\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640aab84-7999-4f0c-987d-a7a5689cef6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee25659-6d8b-4f70-aaa6-fac828286b40",
   "metadata": {},
   "source": [
    "To analyze the difference between Vader and TextBlob in creating sentiment scores, we used bar plots that are color coded to represent the different libraries. TextBlob counts are shown in mediumturquoise, Vader in yellowgreen, and any overlapping counts are shown in green. To create these plots, we used Seaborns countplot() function to create two layers of the plot, one with the continuous scores from the TextBlob functions, and one with the continous scores from Vader. \n",
    "\n",
    "The data reveals that there is a significant difference in the way that each program caluculated the scores. In relation to the Boston Bombings Vader observed significantly more \"Negative\" sentiments than TextBlob. Conversely, TextBlob recorded a much larger sample of \"Neutral\" tweets. However the two programs recognized a similar amount of tweets with a \"Positive\" Sentiment. \n",
    "\n",
    "For Hurricane Sandy both Vader and TextBlob had significantly less Variane within the data. There was not a notable difference in the detection and sorting of different sentiments. Vader detected a slightly larger amount of \"Positive\" tweets, while TextBlob had more \"Negative\". But both programs had a very similar amount of responses with a \"Neutral\" connotation. The data is much more uniform when compaared to the Boston Bombings. It also indicates that people might be more likely the have similar opinions on natural disasters rather than man-made disasters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e4dc3-6ca9-4779-ab1c-0dc938c1fc1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Boston Bombing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce58c4e7-c515-43c3-91e5-c8bfeb6ec465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=\"sentiment_textblob\", data= bomb , label=\"TextBlob\", color='mediumturquoise', alpha=0.5)\n",
    "sns.countplot(x=\"sentiment_vader\", data= bomb , label=\"Vader\", color='yellowgreen', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.title('Distribution of Sentiment Scores from TextBlob and Vader: Boston Bombings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b776783-c4bc-482a-a939-64200f7fe3b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hurricane Sandy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f3067-234b-407f-b2b9-84f85fe2f15a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=\"sentiment_textblob\", data=sandy, label=\"TextBlob\", color='mediumturquoise', alpha=0.5)\n",
    "sns.countplot(x=\"sentiment_vader\", data=sandy , label=\"Vader\", color='yellowgreen', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.title('Distribution of Sentiment Scores from TextBlob and Vader: Hurricane Sandy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea61b7-b558-4ae5-b424-19153ea558e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed10a9d1-7b5d-44d8-87ae-e11ab7a739a9",
   "metadata": {},
   "source": [
    "Topic modeling is part of a larger group of algorithms known as 'unsupervised learning'. 'Unsupervised' because we don't provide the algorithm with predefined labels, it finds structure on its own, and 'learning' because it gets better and better as it processes more data. In order for us to execute Topic Modeling, we had to apply a few functions that will allow us to look at the ‘unsupervised learning’ aspect of Topic Modeling. Using the nltk, we are able to identify the larger theme of the tweets surrounding the Boston Bombing and Hurricane Sandy events. \n",
    "\t\n",
    "First, we cleaned the text in both datasets. Then, used we constructed a topic model by tweaking the two parameters and using the functions `number_topics = 5` and `number_words = 10`. Then, we created and fit the LDA model with a fixed random state to prevent changes with every update by creating `lda = LDA(n_components=number_topics, n_jobs=-1` and `lda.fit(count_data)`.\n",
    "\t\n",
    "In order to view the topics, we created the function ‘def print_topics’, which includes the model, count_vectorizer, and the number_words. We then used Bokeh to graph a topic cluster of the five most talked about things from the events from both the Boston Bombing and Sandy Hurricane events. Because we have two different datasets, it’s important to note that we had to differentiate the code by using _boom and _nature in order to create two different visuals that weren’t the same. By using pyLDAvis we were able to see the results of what words were showing up repeatedly in all the tweets about the two separate events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40a7e6c-dae2-4124-bb0d-1113df530339",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Boston Bombing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3835c-af15-46f6-911a-6fa76cd399d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# We will only use the 'text_cleaned' column for our analysis\n",
    "boom = bomb['clean_text']\n",
    "\n",
    "# Fit and transform the processed titles\n",
    "count_data_boom = count_vectorizer.fit_transform(boom)\n",
    "\n",
    "# Tweak the two parameters below (use int values below 15)\n",
    "number_topics = 5\n",
    "number_words = 10\n",
    "\n",
    "# Create and fit the LDA model with a fixed random state to prevent changes with every update\n",
    "lda_model = LDA(n_components=number_topics, n_jobs=-1, random_state=5)\n",
    "lda_model.fit(count_data_boom)\n",
    "\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names_out()\n",
    "    topic_word_distributions = model.components_\n",
    "    for topic_idx, topic in enumerate(topic_word_distributions):\n",
    "        print(\"\\nTopic #%d:\" % (topic_idx + 1))\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "\n",
    "print_topics(lda_model, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dc41c9-5da1-4984-b87f-67bb06a56d2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "The data reveals that the top 5 Subjects in the Bosston Bombings are: \n",
    "\n",
    "Topic #1:\n",
    "boston rt marathon bombing bomb suspect breaking suspects explosions news\n",
    "\n",
    "- This topic surrounds the initial breaking news of the Boston Bombing. \n",
    "- It surrounds the actual events and actions of the day. \n",
    "- Terms like \"breaking\", \"explosions\", and \"news\" indicate that this event had just \n",
    "occured. \n",
    "\n",
    "\n",
    "Topic #2:\n",
    "boston rt prayforboston marathon old died explosions year people running\n",
    "\n",
    "- This topic surrounds some of the shock and sympathy in the aftermath of the attack. \n",
    "- Users shared their thoughts and prayers through the use of terms like \"#prayforboston\", \"died\", and \"people\".\n",
    "\n",
    "\n",
    "Topic #3:\n",
    "boston rt marathon suspects bombing fbi bombings prayforboston thoughts bostonmarathon\n",
    "\n",
    "- This topic looks at the actual events following the Bombing. \n",
    "- They indicate that the public was sharing information in relation to the initial response to the attack. \n",
    "- Terms like, \"suspects\", \"fbi\", and \"bombing\" demonstrate that the public discourse surrounded justice and resolution. \n",
    "\n",
    "\n",
    "Topic #4:\n",
    "boston rt suspect bombing marathon police bostonmarathon dead bomb suspects\n",
    "\n",
    "- This topic is specifically focussed on the response of law enforcement. \n",
    "- It relates to how the FBI and Boston PD were attempting to locate the extremists. \n",
    "- Terms such as \"suspect\", \"police\", and \"suspects\" demonstrate this.\n",
    "\n",
    "\n",
    "Topic #5:\n",
    "boston rt bombing explosion bostonmarathon obama texas prayforboston martin right\n",
    "\n",
    "- This topic surrounds the political response in the aftermath of the Boston Bombing. \n",
    "- It references aspects of politics through terms like \"Obama\" and \"right\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a895b0-6e92-47c6-8b4c-4c2fbb77fa7f",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec78e31-7fa3-436c-b635-22865132bb52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get topic weights\n",
    "topic_weights = lda_model.transform(count_data_boom)\n",
    "\n",
    "# Array of topic weights    \n",
    "arr_boom = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "arr_boom = arr_boom[np.amax(arr_boom, axis=1) > 0.35]\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "topic_num_boom = np.argmax(arr_boom, axis=1)\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model_boom = TSNE(n_components=2, verbose=1, random_state=5, angle=.99, init='pca')\n",
    "tsne_lda_boom = tsne_model_boom.fit_transform(arr_boom)\n",
    "\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import Legend\n",
    "\n",
    "# Plot the Topic Clusters using Bokeh\n",
    "output_notebook()\n",
    "mycolors_boom = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "plot_boom = figure(title=\"Clustering of Top {} Boston Bombing Topics\".format(number_words), \n",
    "              width=900, height=700)\n",
    "\n",
    "scatter_list_boom = []\n",
    "for topic in np.unique(topic_num_boom):\n",
    "    indices = np.where(topic_num_boom == topic)[0]\n",
    "    scatter = plot_boom.scatter(x=tsne_lda_boom[indices, 0], \n",
    "                                y=tsne_lda_boom[indices, 1], \n",
    "                                color=mycolors_boom[topic])\n",
    "    scatter_list_boom.append(scatter)\n",
    "\n",
    "# Define topic labels\n",
    "topic_labels_boom = ['Topic 1: Initial Breaking News', 'Topic 2: Public Sympathy', \n",
    "                     'Topic 3: Aftershock', 'Topic 4: Law Enforcement', \n",
    "                     'Topic 5: Politics']\n",
    "\n",
    "# Create legend\n",
    "legend_boom = Legend(items=[(label, [scatter]) for label, scatter in zip(topic_labels_boom, scatter_list_boom)],\n",
    "                location='top_left')\n",
    "plot_boom.add_layout(legend_boom, 'right')\n",
    "\n",
    "show(plot_boom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf5ada-4815-459d-b74a-70971bda8d8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## pyLDAvis with Boston Marathon Bombing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f7553-8173-4147-8b69-41f4547ecdc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit and transform the processed titles\n",
    "count_data_boom = count_vectorizer.fit_transform(boom)\n",
    "\n",
    "# Convert the count data to a gensim corpus\n",
    "corpus = gensim.matutils.Sparse2Corpus(count_data_boom.T)\n",
    "\n",
    "# Create a gensim Dictionary\n",
    "dictionary = gensim.corpora.Dictionary.from_corpus(corpus, id2word=dict(zip(range(len(count_vectorizer.get_feature_names_out())), count_vectorizer.get_feature_names_out())))\n",
    "\n",
    "# Create and fit the LDA model with gensim\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=number_topics, random_state=5)\n",
    "\n",
    "# Generate the pyLDAvis visualization\n",
    "panel = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901c3cf8",
   "metadata": {},
   "source": [
    "### Topic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce99680a",
   "metadata": {},
   "source": [
    "The 5 most prevalent topics on Twitter in the wake of the Boston Bombing were fairly standard. The first topic was the initial breaking news of the attack. The second topic surrounds the tragedy and the user's thoughts and prayers for those affected. The third topic is about the general response and the subsequent steps in order to be safer and help people heal. The fourth topic is specifically about law enforcement and their countermeasures to catch the suspects. The last topic surrounds the political response and issues left behind after the attack. \n",
    "\n",
    "It's important to note that there were significantly more \"negative\" tweets in regards to the Boston Bombing. Both Textblob and Vader detected a large sum of tweets that held negative sentiment. Per the data, users tended to view man made disasters more negatively than natural ones. The overall \"negative\" sentiment scores were much higher when compared to Hurricane Sandy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9465fe4-6f71-488b-950a-4edd4e90fe34",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hurricane Sandy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6748e787-ae28-4412-9ceb-03ca1a016e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will only use the 'text_cleaned' column for our analysis\n",
    "natural = sandy['clean_text']\n",
    "\n",
    "# Fit and transform the processed titles\n",
    "count_data_natural = count_vectorizer.fit_transform(natural)\n",
    "\n",
    "# Tweak the two parameters below (use int values below 15)\n",
    "number_topics = 5\n",
    "number_words = 10\n",
    "\n",
    "# Create and fit the LDA model with a fixed random state to prevent changes with every update\n",
    "lda_model = LDA(n_components=number_topics, n_jobs=-1, random_state=5)\n",
    "lda_model.fit(count_data_natural)\n",
    "\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names_out()\n",
    "    topic_word_distributions = model.components_\n",
    "    for topic_idx, topic in enumerate(topic_word_distributions):\n",
    "        print(\"\\nTopic #%d:\" % (topic_idx + 1))\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "\n",
    "print_topics(lda_model, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4944a",
   "metadata": {},
   "source": [
    "The data reveals that the top 5 Subjects following Hurricane Sandy are:\n",
    "\n",
    "Topic #1: hurricane sandy storm rt power lt going really away don\n",
    "\n",
    "- This topic surrounds the destruction of infrastructure in the wake of the hurricane. \n",
    "- The term \"power\" in addition to \"going away\" seems to indicate that users were concerned with the lack of power.\n",
    "\n",
    "Topic #2: hurricane rt sandy just like school new people power don\n",
    "\n",
    "- This topic describes the effect on the day to day activities from Hurricane Sandy. \n",
    "- \"People\" and \"school\" make it seem like people were discussing the disruption of normal activities.\n",
    "\n",
    "Topic #3: hurricane sandy rt frankenstorm stay safe new hit ny apocalypse\n",
    "\n",
    "- This topic surrounded the potential catastrophic event when the hurricane collided with New York City. \n",
    "- It was a reaction to Hurricane Sandy when it headed inland. \n",
    "- Terms like \"hit ny\", \"frankenstorm\", \"and \"stay safe\" indicate this.\n",
    "\n",
    "Topic #4: hurricane rt fuck water went bout gonna house sandy irene\n",
    "\n",
    "- This topic seems to demonstrate personal experiences and attitudes towards storms. \n",
    "- Specifically the term \"f*ck\" is telling that this topic was not a pleasurable talking point.\n",
    "\n",
    "Topic #5: hurricane sandy rt east coast like safe shit new affected\n",
    "\n",
    "- This topic relates to the general safety of those who live on the east coast. \n",
    "- Terms like \"safety\", \"east coast\", and \"affected\" demonstrate this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7779209-1027-4176-952e-d15f5f3ac0f3",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbcc0a8-7cf7-4e6d-9076-78eb00345e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get topic weights\n",
    "topic_weights = lda_model.transform(count_data_natural)\n",
    "\n",
    "# Array of topic weights    \n",
    "arr_natural = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "arr_natural = arr_natural[np.amax(arr_natural, axis=1) > 0.35]\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "topic_num_natural = np.argmax(arr_natural, axis=1)\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model_natural = TSNE(n_components=2, verbose=1, random_state=5, angle=.99, init='pca')\n",
    "tsne_lda_natural = tsne_model_natural.fit_transform(arr_natural)\n",
    "\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import Legend\n",
    "\n",
    "# Plot the Topic Clusters using Bokeh\n",
    "output_notebook()\n",
    "mycolors_natural = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "plot_natural = figure(title=\"Clustering of Top {} Natural Disaster Topics\".format(number_words), \n",
    "              width=900, height=700)\n",
    "\n",
    "scatter_list_natural = []\n",
    "for topic in np.unique(topic_num_natural):\n",
    "    indices = np.where(topic_num_natural == topic)[0]\n",
    "    scatter = plot_natural.scatter(x=tsne_lda_natural[indices, 0], \n",
    "                                y=tsne_lda_natural[indices, 1], \n",
    "                                color=mycolors_natural[topic])\n",
    "    scatter_list_natural.append(scatter)\n",
    "\n",
    "# Define topic labels\n",
    "topic_labels_natural = ['Topic 1: Destruction of Infrastructure', 'Topic 2: Day to Day Effect', \n",
    "                        'Topic 3: NYC Gets Hit', 'Topic 4: Negative Personal Experiences', \n",
    "                        'Topic 5: East Coast Safety']\n",
    "\n",
    "# Create legend\n",
    "legend_natural = Legend(items=[(label, [scatter]) for label, scatter in zip(topic_labels_natural, scatter_list_natural)],\n",
    "                location='top_left')\n",
    "plot_natural.add_layout(legend_natural, 'right')\n",
    "\n",
    "show(plot_natural)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286a83f",
   "metadata": {},
   "source": [
    "### Topic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bc1b9e",
   "metadata": {},
   "source": [
    "The five most popular topics surrounding Hurricane Sandy were also predictable. Generally users tended \n",
    "to focus on a lack of resources and a disruption of everday activities. Additionally, users sent prayers and warnings \n",
    "to those affected by the storm. They also aired their frustrations out and shared their negative attitude towards\n",
    "the hurricane. \n",
    "\n",
    "In comparison with the Boston Bombings, the data reveals that the tweets contained a lower frequency of negative sentiments. Users tended to share tweets with a \"positive\" or \"neutral\" connotation. The data suggests that natural disasters are more likely to contain  positive sentiments in comparsion to man made disasters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68519db9-817f-41da-80d7-a61494991460",
   "metadata": {
    "tags": []
   },
   "source": [
    "## pyLDAvis with Hurricane Sandy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c557f-2462-470a-8eee-9e097c9c725e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit and transform the processed titles\n",
    "count_data_natural = count_vectorizer.fit_transform(natural)\n",
    "\n",
    "# Convert the count data to a gensim corpus\n",
    "corpus = gensim.matutils.Sparse2Corpus(count_data_natural.T)\n",
    "\n",
    "# Create a gensim Dictionary\n",
    "dictionary = gensim.corpora.Dictionary.from_corpus(corpus, id2word=dict(zip(range(len(count_vectorizer.get_feature_names_out())), count_vectorizer.get_feature_names_out())))\n",
    "\n",
    "# Create and fit the LDA model with gensim\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=number_topics, random_state=5)\n",
    "\n",
    "# Generate the pyLDAvis visualization\n",
    "panel = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b03bac-3518-4097-adf6-b5f3061cfb7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Results/Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfbfe45-a183-4c1f-82ce-50cf2d13a4fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sentiment Analysis\n",
    "Taking a look at our first research question, we can see that there are major disparities in the way that TextBlob and Vader calculate sentiment scores for the Boston Bombings tweets. Vader produced nearly twice as many \"negative\" labels as TextBlob, while the opposite effect occurred in \"neutral\" tweets. The positive tweets from both libraries are much fewer in frequencies, but TextBlob and Vader label them very similarly. Since Vader has a wider scope of what gets included in calculating the score, it would be a reasonable assumption that the emojis and capitalizations used in these tweets provide more negative context in a addition to the words written. Without these non-textual cues and components, these tweets can be defined as more neutral as they are in TextBlob's processing. In other words, these disparities in how the tweets are processed can show us how important non-textual aspects of written communication can be important in understanding context.\n",
    "\n",
    "In regards to comparing TextBlob and Vader's processing capabilities between man-made (Boston Bombing) and natural (Hurricane Sandy) disasters, we can clearly see a lot less variability between the two libraries when it comes to Hurricane Sandy. The overall trends are the same with Hurricane Sandy as they are with the Bombings: Vader produces more negative labels while TextBlob produces more positive and neutral labels. However, these differences are much less significant, the counts for labels are distribtued much more evenly. Opposite to the Boston Bombings, the most popular label was \"Positive\", which may imply that negative feelings to Hurricane Sandy, a natural disaster, are not as intense or prevalent as feelings toward a man-made disaster such as the Boston Bombings. Since we can connect the Boston Bombings to rhuman emotion and morality more easily than we can with Hurricane Sandy, these assumptions are logically sensible, but not able to be definitively made based on these types of analyses.\n",
    "\n",
    "Further research could be done to investigate the causes of these discrepancies and would be a great pathway into understand how connecting disaster with humanity may influence the tweets that we post and the feelings we share when disaster strikes, but it's safe to say that TextBlob and Vader's different processing abilities give insight to how emojis can change the sentiments of tweets.\n",
    "\n",
    "\n",
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1bad11-5a68-4d38-a00b-90105e453927",
   "metadata": {},
   "source": [
    "Discussing our third research question, we found that the main topic cluster that are coming up the most in tweets that are ‘on-topic’ for the Boston Marathon Bombing are most involved during the actual events of the Bombing itself. There is indication that many Twitter users that are in the dataset were sharing information in relation to the initial attack, following specific words such as explosions, bombing, and #prayforboston. From the Topic Cluster we can see that the topics themselves start to intertwine as certain words start to mix, however, Topic 5 ends up being the center of everything surrounded by all the other topics. Leading into Topic 5 which was the political response in the aftermath of the Boston Marathon Bombing. Words such as Boston, bombing, explosion, prayforboston, Obama were coming up the most. There was also some on-topic tweets concerning the law enforcement response. Because Textblob and Vader detected such large numbers of tweets that were negative, the negative sentiment scores were much higher than the Hurricane Sandy event.\n",
    "\n",
    "In comparison to the Sandy Hurricane event, the on-topic clusters were more focused on the the relevant terms ‘hurricane, sandy, rt’, and overall seemed less negative when ran in Textblob and Vader. However, salient terms were also pretty relevant in as terms such as f*ck was extremely used to really demonstrate just how un-pleasurable the event truly was. In comparison in terms of the Topic Cluster, Topic 4 which was the topic regarding the more salient terms was the center of the model as everything else revolved around it. Sandy and rt were still very used in the thousands, however, there was a much larger marginal for topic distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
